# -*- coding: utf-8 -*-
"""Data2_TF_UNet3Plus_UsingImageDataGenerator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14O7UGbW2lrBSaFCmeolIALbzjIYuVZvi
"""
'''
!nvidia-smi

from google.colab import drive

drive.mount('/content/drive')

!ls /content/drive/MyDrive/UNet_tensorflow/

import sys
sys.path.append('/content/drive/MyDrive/UNet_tensorflow/')

!pip install keras-unet-collection
'''
import os
import numpy as np
from matplotlib import pyplot as plt
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
from keras_unet_collection import models
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger
from tensorflow.keras.preprocessing.image import ImageDataGenerator

os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'

#New generator with rotation and shear where interpolation that comes with rotation and shear are thresholded in masks. 
#This gives a binary mask rather than a mask with interpolated values. 
seed=24
batch_size= 8

img_data_gen_args = dict(rescale = 1/255.,
                         rotation_range=0,
                      width_shift_range=0,
                      height_shift_range=0,
                      shear_range=0,
                      zoom_range=0,
                      horizontal_flip=False,
                      vertical_flip=False,
                      fill_mode='reflect')

mask_data_gen_args = dict(rescale = 1/255.,  #Original pixel values are 0 and 255. So rescaling to 0 to 1
                        rotation_range=0,
                      width_shift_range=0,
                      height_shift_range=0,
                      shear_range=0,
                      zoom_range=0,
                      horizontal_flip=False,
                      vertical_flip=False,
                      fill_mode='reflect',
                      preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) #Binarize the output again.

#If You need to resize images then add this to the flow_from_directory parameters 
#target_size=(150, 150), #Or whatever the size is for your network

image_data_generator = ImageDataGenerator(**img_data_gen_args)
image_generator = image_data_generator.flow_from_directory("C:/Users/Impro/Desktop/cwh/Data2/train_images/", 
                                                           target_size=(576, 768),
                                                           seed=seed, 
                                                           batch_size=batch_size,
                                                           class_mode=None)  #Very important to set this otherwise it returns multiple numpy arrays 
                                                                            #thinking class mode is binary.

mask_data_generator = ImageDataGenerator(**mask_data_gen_args)
mask_generator = mask_data_generator.flow_from_directory("C:/Users/Impro/Desktop/cwh/Data2/train_masks/", 
                                                         target_size=(576, 768),
                                                         seed=seed, 
                                                         batch_size=batch_size,
                                                         color_mode = 'grayscale',   #Read masks in grayscale
                                                         class_mode=None)


valid_img_generator = image_data_generator.flow_from_directory("C:/Users/Impro/Desktop/cwh/Data2/val_images/", 
                                                               target_size=(576, 768),
                                                               seed=seed, 
                                                               batch_size=batch_size, 
                                                               class_mode=None) #Default batch size 32, if not specified here
valid_mask_generator = mask_data_generator.flow_from_directory("C:/Users/Impro/Desktop/cwh/Data2/val_masks/", 
                                                               target_size=(576, 768),
                                                               seed=seed, 
                                                               batch_size=batch_size, 
                                                               color_mode = 'grayscale',   #Read masks in grayscale
                                                               class_mode=None)  #Default batch size 32, if not specified here


train_generator = zip(image_generator, mask_generator)
val_generator = zip(valid_img_generator, valid_mask_generator)

#from google.colab import drive
#drive.mount('/content/drive')

x = image_generator.next()
y = mask_generator.next()
for i in range(0,1):
    image = x[i]
    mask = y[i]
    plt.subplot(1,2,1)
    plt.imshow(image[:,:,0], cmap='gray')
    plt.subplot(1,2,2)
    plt.imshow(mask[:,:,0])
    plt.show()

#!pip install focal-loss

#Jaccard distance loss mimics IoU. 
from keras import backend as K
def jaccard_distance_loss(y_true, y_pred, smooth=100):
    """
    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)
            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))
    
    The jaccard distance loss is usefull for unbalanced datasets. This has been
    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing
    gradient.
    
    Ref: https://en.wikipedia.org/wiki/Jaccard_index
    
    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96
    @author: wassname
    """
    intersection = K.sum(K.sum(K.abs(y_true * y_pred), axis=-1))
    sum_ = K.sum(K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1))
    jac = (intersection + smooth) / (sum_ - intersection + smooth)
    return (1 - jac) * smooth

#Dice metric can be a great metric to track accuracy of semantic segmentation.
def dice_metric(y_pred, y_true):
    intersection = K.sum(K.sum(K.abs(y_true * y_pred), axis=-1))
    union = K.sum(K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1))
    # if y_pred.sum() == 0 and y_pred.sum() == 0:
    #     return 1.0

    return 2*intersection / union

IMG_HEIGHT = x.shape[1]
IMG_WIDTH  = x.shape[2]
IMG_CHANNELS = x.shape[3]

input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)

#model = build_unet(input_shape)
model = models.unet_3plus_2d(input_shape, n_labels=2, filter_num_down=[64, 128, 256, 512], 
                             filter_num_skip='auto', filter_num_aggregate='auto', 
                             stack_num_down=2, stack_num_up=1, activation='ReLU', output_activation='Sigmoid',
                             batch_norm=True, pool='max', unpool=False, deep_supervision=False, name='unet3plus')

from focal_loss import BinaryFocalLoss

model.compile(optimizer=Adam(lr = 1e-3), loss=BinaryFocalLoss(gamma=2), 
              metrics=[dice_metric])


model.summary()

num_train_imgs = len(os.listdir('C:/Users/Impro/Desktop/cwh/Data2/train_images/train/'))

steps_per_epoch = num_train_imgs //batch_size
epochs = 100

csv_path = "C:/Users/Impro/Desktop/cwh/fit_log_data2/Data2_checkpoint_data.csv"
checkpoint_path = "C:/Users/Impro/Desktop/cwh/fit_log_data2/load_from_disk_Data2_checkpoint_model.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

callbacks = [ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=True, mode='auto', save_freq='epoch', options=None, initial_value_threshold=None),
        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-7, verbose=1),
        CSVLogger(csv_path, append=True),
        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=False)]

model.save_weights(checkpoint_path)

history = model.fit(train_generator, validation_data=val_generator, 
                    steps_per_epoch=steps_per_epoch, 
                    validation_steps=steps_per_epoch, 
                    epochs = epochs,
                    callbacks = callbacks)



model.save('C:/Users/Impro/Desktop/cwh/Data2_UNet3Plus_load_from_disk.hdf5')



#plot the training and validation accuracy and loss at each epoch
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history.history['dice_metric']
#acc = history.history['accuracy']
val_acc = history.history['val_dice_metric']
#val_acc = history.history['val_accuracy']

plt.plot(epochs, acc, 'y', label='Training Dice')
plt.plot(epochs, val_acc, 'r', label='Validation Dice')
plt.title('Training and validation Dice')
plt.xlabel('Epochs')
plt.ylabel('Dice')
plt.legend()
plt.show()

"""Test the model"""

model = tf.keras.models.load_model('C:/Users/Impro/Desktop/cwh/Data2_UNet3Plus_load_from_disk.hdf5', compile=False)

test_img_generator = image_data_generator.flow_from_directory("C:/Users/Impro/Desktop/cwh/Data2/test_images/",
                                target_size=(576, 768), 
                                seed=seed, 
                                batch_size=4, 
                                class_mode=None) #Default batch size 32, if not specified here

test_mask_generator = mask_data_generator.flow_from_directory("C:/Users/Impro/Desktop/cwh/Data2/test_masks/",
                                target_size=(576, 768), 
                                seed=seed, 
                                batch_size=4, 
                                color_mode = 'grayscale',   #Read masks in grayscale
                                class_mode=None)  #Default batch size 32, if not specified here

a = test_img_generator.next()
b = test_mask_generator.next()
for i in range(0,4):
    image = a[i]
    mask = b[i]
    plt.subplot(1,2,1)
    plt.imshow(image[:,:,0], cmap='gray')
    plt.subplot(1,2,2)
    plt.imshow(mask[:,:,0])
    plt.show()

import random
from PIL import Image

n_classes = 2
test_img_number = random.randint(0, a.shape[0]-1)
test_img = a[test_img_number]
ground_truth=b[test_img_number]
#test_img_norm=test_img[:,:,0][:,:,None]
test_img_input=np.expand_dims(test_img, 0)
prediction = (model.predict(test_img_input)[0,:,:,0] > 0.6).astype(np.uint8)
prediction = np.round(prediction).astype(np.uint8) # Convert to integer values
prediction = np.clip(prediction, 0, n_classes - 1) # Clamp values between 0 and n_classes - 1
#prediction_img = Image.fromarray(prediction * 255) # Convert to PIL Image
#prediction_img = prediction_img.convert('L') # Convert to grayscale
#predict_bg = Image.new('RGB', (768, 576), color='black')
#predict_bg.paste(prediction_img, (0, 0))
#prediction = predict_bg # assign predict_bg to prediction variable

plt.figure(figsize=(16, 8))
plt.subplot(231)
plt.title('Testing Image')
plt.imshow(test_img, cmap='gray')
plt.subplot(232)
plt.title('Testing Label')
plt.imshow(ground_truth[:,:,0], cmap='gray')
plt.subplot(233)
plt.title('Prediction on test image')
plt.imshow(prediction, cmap='gray')

plt.show()

#IoU for a single image
from tensorflow.keras.metrics import MeanIoU
n_classes = 2
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(ground_truth[:,:,0], prediction)
print("Mean IoU =", IOU_keras.result().numpy())

import numpy as np

def compute_iou(y_pred, y_true):
    y_pred = np.round(y_pred)
    y_true = np.round(y_true)
    intersection = np.logical_and(y_pred, y_true).sum()
    union = np.logical_or(y_pred, y_true).sum()
    iou = (intersection + 1e-10) / (union + 1e-10)
    return iou

prediction_binary = np.round(prediction).astype(int)
ground_truth_binary = np.round(ground_truth).astype(int)

iou = compute_iou(prediction_binary, ground_truth_binary[:,:,0])
print("IoU is: ", iou)

#Calculate IoU and average
 
import pandas as pd

IoU_values = []
for img in range(0, a.shape[0]):
    temp_img = a[img]
    ground_truth=b[img]
    temp_img_input=np.expand_dims(temp_img, 0)
    prediction = (model.predict(temp_img_input)[0,:,:,0] > 0.5).astype(np.uint8)
    
    IoU = MeanIoU(num_classes=n_classes)
    IoU.update_state(ground_truth[:,:,0], prediction)
    IoU = IoU.result().numpy()
    IoU_values.append(IoU)

    print(IoU)

df = pd.DataFrame(IoU_values, columns=["IoU"])
df = df[df.IoU != 1.0]    
mean_IoU = df.mean().values
print("Mean IoU is: ", mean_IoU)